# ğŸš€ GCP Managed Instance Group + Load Balancer Project
 
## ğŸ“Œ Project Overview

This project demonstrates how to build a **scalable, highly available web application architecture** in Google Cloud Platform (GCP) using:

* Google Cloud Managed Instance Group
* Google Cloud Load Balancing
* Health Checks
* Autoscaling (CPU-based)
* Startup Scripts

The goal of this project was to simulate a real-world production environment where application traffic is distributed across multiple virtual machines and automatically scales based on demand.

---

## ğŸ— Architecture

```
User
  â†“
Global HTTP Load Balancer
  â†“
Backend Service
  â†“
Managed Instance Group (MIG)
  â†“
Multiple VM Instances (Apache Web Server)
```

---

## ğŸ¯ Objectives

* Deploy identical VM instances using Instance Templates
* Automatically distribute traffic across instances
* Enable health checks and auto-healing
* Configure CPU-based autoscaling
* Simulate traffic and test scaling behavior

---

## âš™ï¸ Technologies Used

* Google Compute Engine
* Managed Instance Groups
* Global HTTP Load Balancer
* Health Checks
* Autoscaler
* Debian 12
* Apache Web Server
* gcloud CLI

---

## ğŸ›  Implementation Steps

### 1ï¸âƒ£ Startup Script

Each VM installs and runs Apache automatically:

```bash
#!/bin/bash
apt-get update
apt-get install -y apache2

cat <<EOF > /var/www/html/index.html
<h1>Hello from $(hostname)</h1>
EOF

systemctl start apache2
systemctl enable apache2
```

---

### 2ï¸âƒ£ Instance Template

Created a reusable VM template with:

* e2-micro machine type
* Debian 12 image
* Startup script
* HTTP firewall tag

---

### 3ï¸âƒ£ Managed Instance Group (MIG)

* Initial size: 2 instances
* Auto-healing enabled via health checks
* Backend attached to load balancer

---

### 4ï¸âƒ£ Health Check

HTTP health check configured on port 80 to ensure instance availability.

---

### 5ï¸âƒ£ Global HTTP Load Balancer

Configured:

* Backend service
* URL map
* Target HTTP proxy
* Global forwarding rule (Port 80)

Traffic is evenly distributed across healthy instances.

---

### 6ï¸âƒ£ Autoscaling Configuration

Configured CPU-based autoscaling:

* Target CPU utilization: 60%
* Minimum instances: 2
* Maximum instances: 5

The system automatically scales out during high load and scales in when traffic decreases.

---

## ğŸ§ª Testing & Validation

### âœ” Load Balancing Verification

Repeated browser refresh showed different hostnames:

```
Hello from web-server-xxxx
```

Confirming traffic distribution.

### âœ” Health Check Verification

Backend status:

```
HEALTHY
```

### âœ” Autoscaling Test

Simulated traffic using continuous curl requests and CPU stress testing.

Observed:

* New instances created automatically
* Instances removed after load decreased

---

## ğŸš§ Challenges Faced

* Browser defaulted to HTTPS while only HTTP load balancer was configured.
* Encountered `ERR_CONNECTION_RESET` due to protocol mismatch.
* Resolved by explicitly using:

  ```
  http://<LOAD_BALANCER_IP>
  ```

This reinforced the importance of understanding HTTP vs HTTPS load balancer configurations.

---

## ğŸ§  Key Learnings

* Designing high availability systems in GCP
* Difference between HTTP and HTTPS Load Balancers
* Understanding backend health states
* Debugging load balancer connection issues
* Implementing autoscaling strategies
* Production-style cloud architecture thinking

---

## ğŸ“ˆ Production Concepts Demonstrated

* Horizontal Scaling
* Auto-healing Infrastructure
* Stateless Application Design
* Traffic Distribution
* Fault Tolerance

---

## ğŸ† Outcome

Successfully built a scalable, fault-tolerant web infrastructure in GCP that:

* Automatically distributes traffic
* Detects and replaces failed instances
* Scales based on CPU usage
* Mimics real-world production environments

---

## ğŸ“Œ Future Improvements

* Add HTTPS Load Balancer with SSL certificate
* Configure HTTP â†’ HTTPS redirection
* Use Terraform for Infrastructure as Code
* Integrate monitoring with Cloud Monitoring
* Deploy custom domain

**Author**
Amulya
